{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAN_mk9EHF31"
      },
      "source": [
        "<h1><center>Translate COCO</center></h1>\n",
        "\n",
        "\n",
        "<!-- <center>Author: </center> -->\n",
        "\n",
        "<b>github:</b> [ml_project_image_cap](https://github.com/Farhana100/ml_project_image_cap)\n",
        "\n",
        "<!-- <b>paper:</b> [TIST: Transcriptome and Histopathological Image Integrative Analysis for Spatial Transcriptomics](https://doi.org/10.1016/j.gpb.2022.11.012) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtaS4jzFQJsA"
      },
      "source": [
        "[![Open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19L0CG9cCwB4CjwnBc-y83AsXvWmfFKY9?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuqiTKaCIbE1"
      },
      "source": [
        "### dependency installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFqi3ZvVIdj5"
      },
      "outputs": [],
      "source": [
        "!pip install googletrans==3.1.0a0 # specific version, or else gives error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9kZ28BwK_Rr"
      },
      "source": [
        "### data download\n",
        "source: [cocodataset](https://cocodataset.org/#download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnxHIn9pLKlB"
      },
      "source": [
        "#### 2017 train/val\n",
        "\n",
        "already saved in drive. get from there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJnu5n8eLsSz"
      },
      "source": [
        "##### image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEFgh95SLFGb"
      },
      "outputs": [],
      "source": [
        "# !wget \"http://images.cocodataset.org/zips/train2017.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JntO33rlMENJ"
      },
      "outputs": [],
      "source": [
        "# !wget \"http://images.cocodataset.org/zips/val2017.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYpeZEZ0L4dp"
      },
      "source": [
        "##### captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofB8WcygL6XM"
      },
      "outputs": [],
      "source": [
        "# !wget \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqrz88C9GwYj"
      },
      "source": [
        "#### copy from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM3UiK2CwfQ3",
        "outputId": "f7804d7d-e7f5-4541-8af0-3e2278297e72"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h3>mount drive</h3></center>\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZwKDHucwvbg"
      },
      "outputs": [],
      "source": [
        "!rsync -ah --progress \"/content/drive/MyDrive/My Drive (1705092)/Study Materials/Level 4 - Term 2/CSE471-472/CSE472/ML project/data/coco-dataset-2017/annotations\" \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3-EkzvQvxDIh"
      },
      "outputs": [],
      "source": [
        "#@markdown <center><h3>unmount drive</h3></center>\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_svgE5-xIRFI"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYxLO1TtHE_j"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator as tr\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0YU6QnNIV25"
      },
      "source": [
        "### function def"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukMRy4f7OptM"
      },
      "outputs": [],
      "source": [
        "def refine_json(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        data_raw = json.load(f)\n",
        "\n",
        "    images = data_raw['images']\n",
        "    annotations = data_raw['annotations']\n",
        "\n",
        "\n",
        "    records = dict()\n",
        "    for img in images:\n",
        "        record = dict()\n",
        "\n",
        "        record['id'] = img['id']\n",
        "        record['file_name'] = img['file_name']\n",
        "        record['captions'] = list()\n",
        "\n",
        "        records[img['id']] = record\n",
        "\n",
        "    \n",
        "    for ann in annotations:\n",
        "        records[ann['image_id']]['captions'].append(ann['caption'])\n",
        "\n",
        "\n",
        "    # json dump records\n",
        "    refined_filepath = f'{filepath.parent}/{filepath.stem}_refined.json'\n",
        "    with open(refined_filepath, 'w', encoding='utf-8') as f:\n",
        "        json.dump(records, f, indent=4)\n",
        "    \n",
        "    return refined_filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbGjyXUPITfF"
      },
      "outputs": [],
      "source": [
        "def get_records(refined_path):\n",
        "    refined_path = Path(refined_path)\n",
        "\n",
        "    data_ref = None\n",
        "    with open(refined_path, 'r', encoding='utf-8') as f:\n",
        "        data_ref = json.load(f)\n",
        "\n",
        "    if data_ref is None:\n",
        "        raise Exception('No data found in refined file')\n",
        "\n",
        "    return data_ref if data_ref else []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_BSYtNWJMUC"
      },
      "outputs": [],
      "source": [
        "def translate(text, src='en', dest='bn'):\n",
        "    translator = tr()\n",
        "    result = translator.translate(text, src=src, dest=dest)\n",
        "\n",
        "    result = [r.text for r in result]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MEck5JpCUVP"
      },
      "outputs": [],
      "source": [
        "def save_temp(json_obj, save_path, count):\n",
        "    save_path = Path(save_path)\n",
        "    save_path = f'{save_path.parent}/{save_path.stem}_translated_{count}.json'\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(json_obj, f, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEXzIfh2JS12"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bdEO8IcgI1Y"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--refine', dest='refine', default=False, action='store_true')\n",
        "parser.add_argument('--translate', dest='translate', default=False, action='store_true')\n",
        "parser.add_argument(dest='path', type=str, help='input json path')\n",
        "parser.add_argument('--start_from', dest='start_from', default=0, type=int, help='starting index of key')\n",
        "parser.add_argument('--save_path', dest='save_path', default='.', type=str, help='output json path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81DNISHyjd9t"
      },
      "outputs": [],
      "source": [
        "args =  parser.parse_args(args=['--refine', '--translate', '/content/annotations/captions_train2017.json', '--save_path', '/content/drive/MyDrive/My Drive (1705092)/Study Materials/Level 4 - Term 2/CSE471-472/CSE472/ML project/data/coco-dataset-2017/annotations/captions_train2017.json'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkjtWGBVJQHX"
      },
      "outputs": [],
      "source": [
        "if args.refine:\n",
        "    print('refining...')\n",
        "    raw_path = args.path\n",
        "    refined_path = refine_json(filepath=raw_path)\n",
        "    print('done')\n",
        "\n",
        "if args.translate:\n",
        "    if args.refine:\n",
        "        # given path was raw\n",
        "        refined_path = refined_path\n",
        "    else:\n",
        "        # given path was refined\n",
        "        refined_path = args.path\n",
        "    \n",
        "    records = get_records(refined_path=refined_path)\n",
        "    translated_records = records.copy()\n",
        "    records_keys = list(records.keys())\n",
        "    records_keys = records_keys[args.start_from:]\n",
        "\n",
        "    print('translating...')\n",
        "    done_count = args.start_from\n",
        "    for id in tqdm(records_keys):\n",
        "        caps = translated_records[id]['captions']\n",
        "        new_caps = translate(caps)\n",
        "        translated_records[id]['captions'] = new_caps\n",
        "        done_count += 1\n",
        "        if done_count % 500 == 0:\n",
        "            print('saving temp...')\n",
        "            save_temp(json_obj=translated_records, save_path=args.save_path, count=done_count)\n",
        "    print('done')\n",
        "\n",
        "    if args.save_path is None or args.save_path == \".\" or args.save_path == \"\" or args.save_path == \" \":\n",
        "        save_path = f'{Path(refined_path).parent}/{Path(refined_path).stem}_translated.json'\n",
        "    else:\n",
        "        save_path = args.save_path\n",
        "\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(translated_records, f, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xuqiTKaCIbE1",
        "WnxHIn9pLKlB",
        "XJnu5n8eLsSz",
        "_svgE5-xIRFI"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
